# Automotive-Data-Analysis-Competition
2024 자동차 데이터 분석 경진대회

![image](https://github.com/user-attachments/assets/3f636169-6ec2-4df8-8168-0c18f4e59e78)


## Result

- public: 0.94467 (6th)
- private: 0.94457 (2nd)
- awards: 최우수상 (2nd / 877명)

## 주최/주관

- 주최: 산업통상자원부, 한국산업기술진흥원
- 주관: 한국자동차연구원, 대구디지털혁신진흥원
- 운영: 데이콘

## Task

프롬프트 엔지니어링 | ChatGPT | 분류 | Macro F1 Score

## 대회 접근법

본 대회는 gpt-3.5 turbo 모델을 이용하여 프롬프트 엔지니어링을 통해 자동자 관련 데이터를 분류하는 것이었습니다. 

하지만 이때 여러 제약 조건이 존재했습니다. 

### 제약 조건

1. gpt 모델 응답이 40개의 행으로 각각 0 또는 1의 답변으로만 구성되지 않는다면 0점
2. system + user Prompt의 토큰 개수가 16000을 초과하는 경우 0점
3. LLM 특성상 동일한 프롬프트 제출물에도 다른 결과가 도출 될 수 있음

따라서 높은 점수를 얻기 위해서는 제한된 토큰 수 내에서 지정된 출력 규칙을 준수하여 최대한의 정확도를 달성해야 했습니다. 

이를 위해 두 가지 문제 해결 전략을 세웠습니다.

### 문제 해결 전략

#### 전략 1. ‘notes’ 컬럼 사용 X

train 데이터에는 ID, Language, Title, Notes 컬럼이 존재했습니다. 이때 Notes 컬럼은 다른 컬럼들에 비해 가장 많은 토큰 수를 차지하고 있었고, 단어적 의미로 보았을 때 title 컬럼이 notes의 정보를 충분히 요약하고 있다고 가정했습니다. 이를 실제로 검증하기 위해 Sentence-Bert 모델을 이용해서 두 컬럼 간의 코사인 유사도를 계산하였고, 실제로 모든 train 데이터에서 0.5 이상의 값이 도출되었습니다. 

따라서 notes 컬럼을 사용하지 않음으로써 토큰 수를 줄이고 내용이 길어질 수록 모델이 잘 학습하지 못하는 한계점을 해결했습니다.

#### 전략 2. 샘플 순차 인덱싱

본 대회에서는 무조건 응답이 40개의 행으로 자동차 관련 데이터라면 1, 그렇지 않으면 0을 출력해야 했습니다. 기존 데이터의 ID는 ‘TRAIN_00’과 같이 1이 아닌 0으로 시작하기 때문에, 모델이 40개가 아닌 39개의 답을 출력하는 등 꽤 혼동하는 모습을 보았습니다. 

따라서 이를 해결하기 위해 각 샘플을 1 ~40 까지 숫자 인덱스로 명확하게 구분하여 모델이 일관된 구조를 유지하고 특정 샘플에 대한 편향을 방지하여 출력의 강건성을 보장했습니다.

### 프롬프트 설계 전략

#### 전략 1. 단 한번의 질문과 답변

본 대회에서는 system prompt와 user prompt를 구분지어 설계할 수 있었습니다. 본래 system prompt에서는 AI의 역할과 행동 방식 등을 설정하고 user prompt 에서는 실질적인 질문이나 요구사항을 전달합니다. 하지만 이번 대회에서는 단 한 번의 질문과 대답으로 평가되는 특수한 상황이기 때문에 system과 user 본래 역할이 무의미해집니다. 

따라서 Self-Attention 메커니즘에 따라 모델이 중요한 정보를 먼저 인식하도록 user에 요청해야 할 구체적인 지시 사항을 system에 입력하여 작업 지시 뿐만 아니라 데이터 포맷과 언어 정보도 중요하게 처리할 수 있도록 프롬프트를 설계했습니다.

#### 전략 2. 언어 인식 한계 극복

제공된 데이터는 각국의 다양한 언어로 이루어져 있으며, 이웃된 샘플 간 언어가 서로 다름을 확인했습니다. 이를 그대로 모델에 입력해야 했기에, 데이터의 언어가 일관되지 않아 제대로 이를 인식하지 못하고 정확도가 떨어졌습니다.  GPT는 단일 시퀀스로 입력된 데이터를 처리하는 자연어 처리 모델인데, 이 과정에서 서로 다른 언어가 연속적으로 나타나면 문맥상의 흐름이 깨져 언어의 전환을 제대로 감지하지 못하거나 문법적 구조와 표현 방식의 차이로 인해 인식이 혼동될 수 있습니다. 

따라서 언어가 전환될 때 명확한 경계를 설정하는 전략으로 구분자 ‘//’를 도입했습니다. GPT에게 언어 전환이 일어나는 지점을 명확히 알려주어 새로운 언어의 처리를 시작하도록 의도하고, 이전 언어의 문맥이 새 언어에 영향을 미치지 않도록 했습니다. 또한 각 언어의 문법 차이로 인한 오류를 방지하여 성능을 향상시켰습니다.

### 프롬프트 최적화 과정

#### 전략 1. 프롬프트 확인 자동화

이번 대회에서 고려해야 할 점은 동일 프롬프트를 제출해도 동일한 성능이 보장되지 않는 것이었습니다. 따라서 최대한 강건하고 동일하게 출력되는 것을 증명해야 합니다. 이를 위해 중심극한정리에 기반하여 하나의 프롬프트의 결과를 총 30번 확인하여 최소한의 자원으로 최대한의 신뢰성을 확보하며 최적화를 진행했습니다. 이때 사용된 데이터는 원본 Train 데이터를 40개의 샘플로 증강하여 검증했습니다. 이렇게 강건성 검증을 통과한 프롬프트를 최종적으로 제출하였고 그 결과, Validation, Public, Private 모두 동일한 결과를 도출하며 이는 운이 아님을 증명했습니다.

#### 전략 2. feature selection

불피요한 토큰을 줄이기 위해 앞서 언급했던 ‘Notes’  컬럼을 사용하지 않는 전략을 기반으로, 프롬프트에 여러가지 언어가 존재한다는 것을 인지하게 하면서 ‘Language’ 컬럼을 drop하여 토큰을 절약했습니다.

#### 전략 3. 개조식 프롬프트

간결한 표현과 필요한 정보에만 집중시키면서 토큰을 절약하고 더욱 명확한 구조와 일관성을 유지하며 정확도 상승을 유도했습니다.

## Model
GPT3.5-turbo-0125 (temperature : 0.4)
